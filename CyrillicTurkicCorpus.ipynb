{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2014642b",
   "metadata": {},
   "source": [
    "# Cyrillic Dataset of Turkic languages spoken in Russia and in former USSR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a577",
   "metadata": {},
   "source": [
    "https://www.cambridge.org/core/books/abs/communicating-with-asia/russian-and-turkic-languages-in-central-asia/D6537B03A7F97DF870BBDF21A2536A02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2ad80",
   "metadata": {},
   "source": [
    "## The Dataset is a part of the Leipzig Corpora (Wikipedia) Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fec417",
   "metadata": {},
   "source": [
    "D. Goldhahn, T. Eckart & U. Quasthoff: Building Large Monolingual Dictionaries at the Leipzig Corpora Collection: From 100 to 200 Languages.\n",
    "In: Proceedings of the 8th International Language Resources and Evaluation (LREC'12), 2012 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65f40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee372c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/bak_wikipedia_2021_100K/bak_wikipedia_2021_100K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/sah_wikipedia_2021_100K/sah_wikipedia_2021_100K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/krc_wikipedia_2016_10K/krc_wikipedia_2016_10K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/tyv_wikipedia_2021_10K/tyv_wikipedia_2021_10K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/kir_wikipedia_2021_100K/kir_wikipedia_2021_100K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/tat_wikipedia_2021_100K/tat_wikipedia_2021_100K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/kaz_wikipedia_2021_100K/kaz_wikipedia_2021_100K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/chv_wikipedia_2021_10K/chv_wikipedia_2021_10K-sentences.txt',\n",
       " '/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/rus_wikipedia_2021_100K/rus_wikipedia_2021_100K-sentences.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"/Users/tatiana/Desktop/Codes/NLP/TurkRusClassification/\"\n",
    "file_list = glob.glob(os.path.join(folder_path, \"**/*sentences.txt\"), recursive=True)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072d0868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bak_wikipedia_2021_100K-sentences.txt: 100000it [00:13, 7232.92it/s]\n",
      "Processing sah_wikipedia_2021_100K-sentences.txt: 100000it [00:13, 7259.85it/s]\n",
      "Processing krc_wikipedia_2016_10K-sentences.txt: 10000it [00:01, 7718.51it/s]\n",
      "Processing tyv_wikipedia_2021_10K-sentences.txt: 10000it [00:01, 7819.67it/s]\n",
      "Processing kir_wikipedia_2021_100K-sentences.txt: 100000it [00:13, 7149.12it/s]\n",
      "Processing tat_wikipedia_2021_100K-sentences.txt: 100000it [00:13, 7399.31it/s]\n",
      "Processing kaz_wikipedia_2021_100K-sentences.txt: 100000it [00:13, 7251.89it/s]\n",
      "Processing chv_wikipedia_2021_10K-sentences.txt: 10000it [00:01, 7825.48it/s]\n",
      "Processing rus_wikipedia_2021_100K-sentences.txt: 100000it [00:14, 7071.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file_path in file_list:\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        language = file_name.split(\"_\")[0]\n",
    "\n",
    "        for i, line in tqdm(enumerate(f), desc=f\"Processing {file_name}\"):\n",
    "            sentence = line.strip().split(\"\\t\")\n",
    "            dfs.append(pd.DataFrame({'index': i, 'text': sentence[1], 'label': language}, index=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4e7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcab21c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bak    100000\n",
       "sah    100000\n",
       "kir    100000\n",
       "tat    100000\n",
       "kaz    100000\n",
       "rus    100000\n",
       "krc     10000\n",
       "tyv     10000\n",
       "chv     10000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f279ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"1001 кисә\"нең Ханна һөйләгән хикәйәләре ингән...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>«112-се Башҡорт атлы дивизияһы яугире Шафиҡов ...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>«…11 февралдә 163 һәм 219 уҡсылар полкы Нарва ...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>«121», Дмитрий Пригов тексына ирҙәр тауышы һәм...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>«12» фильмы өсөн Венеция кинофестиваленең (200...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629995</th>\n",
       "      <td>99995</td>\n",
       "      <td>· 弄啥类，что за вещь, что делать—意为“干什么呢”。</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629996</th>\n",
       "      <td>99996</td>\n",
       "      <td>服部 安信) — друг Ямато, популярный у девушек лове...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629997</th>\n",
       "      <td>99997</td>\n",
       "      <td>» (カミュなんて知らない, 2005), демонстрировавшийся в ра...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629998</th>\n",
       "      <td>99998</td>\n",
       "      <td>» (系辞传 xìcí zhuàn), который входит в состав та...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629999</th>\n",
       "      <td>99999</td>\n",
       "      <td>能 — Энергия, сила; могу, способен.</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text label\n",
       "0           0  \"1001 кисә\"нең Ханна һөйләгән хикәйәләре ингән...   bak\n",
       "1           1  «112-се Башҡорт атлы дивизияһы яугире Шафиҡов ...   bak\n",
       "2           2  «…11 февралдә 163 һәм 219 уҡсылар полкы Нарва ...   bak\n",
       "3           3  «121», Дмитрий Пригов тексына ирҙәр тауышы һәм...   bak\n",
       "4           4  «12» фильмы өсөн Венеция кинофестиваленең (200...   bak\n",
       "...       ...                                                ...   ...\n",
       "629995  99995            · 弄啥类，что за вещь, что делать—意为“干什么呢”。   rus\n",
       "629996  99996  服部 安信) — друг Ямато, популярный у девушек лове...   rus\n",
       "629997  99997  » (カミュなんて知らない, 2005), демонстрировавшийся в ра...   rus\n",
       "629998  99998  » (系辞传 xìcí zhuàn), который входит в состав та...   rus\n",
       "629999  99999                 能 — Энергия, сила; могу, способен.   rus\n",
       "\n",
       "[630000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4304e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff53681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cyrillic_turkic_langs.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e6d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14d44b24",
   "metadata": {},
   "source": [
    "## Equally splitting the corpus for train, test, and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41bfea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"1001 кисә\"нең Ханна һөйләгән хикәйәләре ингән...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>«112-се Башҡорт атлы дивизияһы яугире Шафиҡов ...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>«…11 февралдә 163 һәм 219 уҡсылар полкы Нарва ...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«121», Дмитрий Пригов тексына ирҙәр тауышы һәм...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>«12» фильмы өсөн Венеция кинофестиваленең (200...</td>\n",
       "      <td>bak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629995</th>\n",
       "      <td>· 弄啥类，что за вещь, что делать—意为“干什么呢”。</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629996</th>\n",
       "      <td>服部 安信) — друг Ямато, популярный у девушек лове...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629997</th>\n",
       "      <td>» (カミュなんて知らない, 2005), демонстрировавшийся в ра...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629998</th>\n",
       "      <td>» (系辞传 xìcí zhuàn), который входит в состав та...</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629999</th>\n",
       "      <td>能 — Энергия, сила; могу, способен.</td>\n",
       "      <td>rus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "0       \"1001 кисә\"нең Ханна һөйләгән хикәйәләре ингән...   bak\n",
       "1       «112-се Башҡорт атлы дивизияһы яугире Шафиҡов ...   bak\n",
       "2       «…11 февралдә 163 һәм 219 уҡсылар полкы Нарва ...   bak\n",
       "3       «121», Дмитрий Пригов тексына ирҙәр тауышы һәм...   bak\n",
       "4       «12» фильмы өсөн Венеция кинофестиваленең (200...   bak\n",
       "...                                                   ...   ...\n",
       "629995            · 弄啥类，что за вещь, что делать—意为“干什么呢”。   rus\n",
       "629996  服部 安信) — друг Ямато, популярный у девушек лове...   rus\n",
       "629997  » (カミュなんて知らない, 2005), демонстрировавшийся в ра...   rus\n",
       "629998  » (系辞传 xìcí zhuàn), который входит в состав та...   rus\n",
       "629999                 能 — Энергия, сила; могу, способен.   rus\n",
       "\n",
       "[600000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"cyrillic_turkic_langs.csv\", encoding=\"utf-8\")\n",
    "\n",
    "df_krc_tyv = df[df[\"label\"].isin([\"krc\",\"tyv\",\"chv\"])]\n",
    "df = df[~df[\"label\"].isin([\"krc\",\"tyv\",\"chv\"])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b370f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_krc_tyv = df_krc_tyv.groupby('label')\n",
    "lang_krc_tyv_dfs = [lang_df_kt for _, lang_df_kt in languages_krc_tyv]\n",
    "#lang_krc_tyv_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90e042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = df.groupby('label')\n",
    "lang_full_dfs = [lang_df for _, lang_df in languages]\n",
    "#lang_full_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "341afb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, test_dfs, valid_dfs = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eed6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_df in lang_krc_tyv_dfs:\n",
    "    train_df, test_valid_df = train_test_split(lang_df, test_size=0.2, random_state=42)\n",
    "    test_df, valid_df = train_test_split(test_valid_df, test_size=0.5, random_state=42)\n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.append(test_df)\n",
    "    valid_dfs.append(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1638b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_df in lang_full_dfs:\n",
    "    lang_df = lang_df.sample(n=10000, random_state=42)\n",
    "    train_df, test_valid_df = train_test_split(lang_df, test_size=0.2, random_state=42)\n",
    "    test_df, valid_df = train_test_split(test_valid_df, test_size=0.5, random_state=42)\n",
    "    #print(train_df)\n",
    "    \n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.append(test_df)\n",
    "    valid_dfs.append(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89900cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecd0774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = pd.concat(train_dfs)\n",
    "train_dfs = train_dfs.sample(frac=1).reset_index(drop=True)\n",
    "train_dfs = train_dfs.reset_index(drop=True)\n",
    "\n",
    "test_dfs = pd.concat(test_dfs)\n",
    "test_dfs = test_dfs.sample(frac=1).reset_index(drop=True)\n",
    "test_dfs = test_dfs.reset_index(drop=True)\n",
    "\n",
    "valid_dfs = pd.concat(valid_dfs)\n",
    "valid_dfs = valid_dfs.sample(frac=1).reset_index(drop=True)\n",
    "valid_dfs = valid_dfs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0173fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs.to_csv(\"train.csv\", encoding=\"utf-8\", index=False)\n",
    "test_dfs.to_csv(\"test.csv\", encoding=\"utf-8\", index=False)\n",
    "valid_dfs.to_csv(\"valid.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343a42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
